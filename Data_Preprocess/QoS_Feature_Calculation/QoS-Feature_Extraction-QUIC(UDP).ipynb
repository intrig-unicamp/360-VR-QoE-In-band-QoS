{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scapy.all import *\n",
    "import numpy as np\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57fca50",
   "metadata": {},
   "source": [
    "#### Filtering UDP/QUIC packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22caef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcap_filter(path):\n",
    "    try:\n",
    "        os.system('tcpdump -r  '+ str(path)+'.pcap'+' -w ' + str(path) + '-0.pcap '+ 'udp')\n",
    "        os.system('tcpdump -r  '+ str(path)+'-0.pcap'+' -w ' + str(path) + '-1.pcap '+ 'host 10.0.0.1')\n",
    "        #os.system('rm -r  '+ str(path)+'.pcap')\n",
    "        print('ok')\n",
    "        \n",
    "    except:\n",
    "        print(path)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd252a9",
   "metadata": {},
   "source": [
    "#### QoS features from UDP/QUIC packets and flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcap_processing(path):\n",
    "\n",
    "    try:\n",
    "        # dataframe declare with all columns name  # throughput(bps), packet size(bytes), inter-arrival time(second)\n",
    "        data = pd.DataFrame(columns=['TP_D_avg', 'TP_D_max', 'TP_D_min', 'TP_D_medn', 'TP_D_std',\n",
    "                                     'TP_D_10p', 'TP_D_20p', 'TP_D_30p', 'TP_D_40p', 'TP_D_50p', 'TP_D_60p', 'TP_D_70p', 'TP_D_80p', 'TP_D_90p',\n",
    "                                     'TP_D_F25_avg', 'TP_D_F50_avg', 'TP_D_L25_avg', 'TP_D_L50_avg',\n",
    "\n",
    "                                     'TP_U_avg', 'TP_U_max', 'TP_U_min', 'TP_U_medn', 'TP_U_std',\n",
    "                                     'TP_U_10p', 'TP_U_20p', 'TP_U_30p', 'TP_U_40p', 'TP_U_50p', 'TP_U_60p', 'TP_U_70p', 'TP_U_80p', 'TP_U_90p',\n",
    "                                     'TP_U_F25_avg', 'TP_U_F50_avg', 'TP_U_L25_avg', 'TP_U_L50_avg',\n",
    "\n",
    "                                     'PC_D_total', 'PC_D_avg', 'PC_D_max', 'PC_D_min', 'PC_D_medn', 'PC_D_std',\n",
    "                                     'PC_D_10p', 'PC_D_20p', 'PC_D_30p', 'PC_D_40p', 'PC_D_50p', 'PC_D_60p', 'PC_D_70p', 'PC_D_80p', 'PC_D_90p',\n",
    "                                     'PC_D_F25_total', 'TP_D_F50_total', 'PC_D_L25_total', 'PC_D_L50_total',\n",
    "\n",
    "                                     'PC_U_total', 'PC_U_avg', 'PC_U_max', 'PC_U_min', 'PC_U_medn', 'PC_U_std',\n",
    "                                     'PC_U_10p', 'PC_U_20p', 'PC_U_30p', 'PC_U_40p', 'PC_U_50p', 'PC_U_60p', 'PC_U_70p', 'PC_U_80p', 'PC_U_90p',\n",
    "                                     'PC_U_F25_total', 'TP_U_F50_total', 'PC_U_L25_total', 'PC_U_L50_total',\n",
    "\n",
    "                                     'PS_D_avg', 'PS_D_max', 'PS_D_min', 'PS_D_medn', 'PS_D_std',\n",
    "                                     'PS_D_10p', 'PS_D_20p', 'PS_D_30p', 'PS_D_40p', 'PS_D_50p', 'PS_D_60p', 'PS_D_70p', 'PS_D_80p', 'PS_D_90p',\n",
    "                                     'PS_D_F25_avg', 'PS_D_F50_avg', 'PS_D_L25_avg', 'PS_D_L50_avg',\n",
    "\n",
    "                                     'PS_U_avg', 'PS_U_max', 'PS_U_min', 'PS_U_medn', 'PS_U_std',\n",
    "                                     'PS_U_10p', 'PS_U_20p', 'PS_U_30p', 'PS_U_40p', 'PS_U_50p', 'PS_U_60p', 'PS_U_70p', 'PS_U_80p', 'PS_U_90p',\n",
    "                                     'PS_U_F25_avg', 'PS_U_F50_avg', 'PS_U_L25_avg', 'PS_U_L50_avg',\n",
    "\n",
    "                                     'IAT_D_avg', 'IAT_D_max', 'IAT_D_min', 'IAT_D_medn', 'IAT_D_std',\n",
    "                                     'IAT_D_10p', 'IAT_D_20p', 'IAT_D_30p', 'IAT_D_40p', 'IAT_D_50p', 'IAT_D_60p', 'IAT_D_70p', 'IAT_D_80p', 'IAT_D_90p',\n",
    "                                     'IAT_D_F25_avg', 'IAT_D_F50_avg', 'IAT_D_L25_avg', 'IAT_D_L50_avg',\n",
    "\n",
    "                                     'IAT_U_avg', 'IAT_U_max', 'IAT_U_min', 'IAT_U_medn', 'IAT_U_std',\n",
    "                                     'IAT_U_10p', 'IAT_U_20p', 'IAT_U_30p', 'IAT_U_40p', 'IAT_U_50p', 'IAT_U_60p', 'IAT_U_70p', 'IAT_U_80p', 'IAT_U_90p',\n",
    "                                     'IAT_U_F25_avg', 'IAT_U_F50_avg', 'IAT_U_L25_avg', 'IAT_U_L50_avg'\n",
    "\n",
    "                                     ])\n",
    "\n",
    "        # read the pcap from given path\n",
    "        pcap = rdpcap(str(path)+'-1.pcap')\n",
    "\n",
    "        pcaplen = len(pcap)\n",
    "        pcaptime_t = int(pcap[pcaplen-1].time - pcap[0].time)\n",
    "        print(pcaptime_t)\n",
    "        pcaptime_h = math.ceil(pcaptime_t/2)\n",
    "        print(pcaptime_h)\n",
    "        pcaptime_q = math.ceil(pcaptime_t/4)\n",
    "        print(pcaptime_q)\n",
    "\n",
    "\n",
    "        # define time-granularity\n",
    "        granularity = 1; \n",
    "\n",
    "        # define threshold values\n",
    "        dthreshold = 1\n",
    "        uthreshold = 1\n",
    "\n",
    "        # initialize start points\n",
    "        dstart = 0\n",
    "        ustart = 0\n",
    "\n",
    "        dinit_pt =0;uinit_pt =0;   \n",
    "\n",
    "        # define variables\n",
    "        dpcount, upcount, dpcount100, upcount100 = 0, 0, 0, 0\n",
    "        dvolume, uvolume, dvolume100, uvolume100 = 0, 0, 0, 0\n",
    "\n",
    "        dtp, utp, dtp100, utp100 = [], [], [], []\n",
    "        dtdif, utdif, dtdif100, utdif100 = [], [], [], []\n",
    "     \n",
    "        dpktime, upktime, dpktime100, upktime100 = [], [], [], []\n",
    "        dpktime_fh, upktime_fh, dpktime100_fh, upktime100_fh = [], [], [], []\n",
    "        dpktime_lh, upktime_lh, dpktime100_lh, upktime100_lh = [], [], [], []\n",
    "        dpktime_fq, upktime_fq, dpktime100_fq, upktime100_fq = [], [], [], []\n",
    "        dpktime_lq, upktime_lq, dpktime100_lq, upktime100_lq = [], [], [], []\n",
    "\n",
    "        diat, uiat, diat100, uiat100 = [], [], [], []\n",
    "        diat_fh, uiat_fh, diat100_fh, uiat100_fh = [], [], [], []\n",
    "        diat_lh, uiat_lh, diat100_lh, uiat100_lh = [], [], [], []\n",
    "        diat_fq, uiat_fq, diat100_fq, uiat100_fq = [], [], [], []\n",
    "        diat_lq, uiat_lq, diat100_lq, uiat100_lq = [], [], [], []\n",
    "\n",
    "        dps, ups, dps100, ups100 = [], [], [], []\n",
    "        dps_fh, ups_fh, dps100_fh, ups100_fh = [], [], [], []\n",
    "        dps_lh, ups_lh, dps100_lh, ups100_lh = [], [], [], []\n",
    "        dps_fq, ups_fq, dps100_fq, ups100_fq = [], [], [], []\n",
    "        dps_lq, ups_lq, dps100_lq, ups100_lq = [], [], [], []\n",
    "\n",
    "\n",
    "        # iterating through each packet from the pcap file\n",
    "        for p in pcap:\n",
    "\n",
    "            # downlink <------------------- (Server - source '10.0.0.251')\n",
    "            if (p.haslayer(UDP)) and (p[IP].src == '10.0.0.251'):\n",
    "\n",
    "                # <-------per second based: throughput and packet number\n",
    "                if (p.time-pcap[0].time) <= dthreshold and (p.time-pcap[0].time) >= dstart:\n",
    "\n",
    "                    dvolume = dvolume + (int(len(p[IP]))*8)\n",
    "                    dpcount = dpcount + 1\n",
    "\n",
    "                else:\n",
    "\n",
    "                    dtp.append(dvolume/granularity)\n",
    "\n",
    "                    dpc.append(dpcount)\n",
    "\n",
    "                    dvolume = 0\n",
    "                    dpcount = 0\n",
    "\n",
    "                    dvolume = dvolume + (int(len(p[IP]))*8)\n",
    "                    dpcount = dpcount + 1\n",
    "\n",
    "                    dthreshold = dthreshold + 1\n",
    "                    dstart = dstart + 1\n",
    "\n",
    "                # <---------- per packet based iat and packet size for entire session\n",
    "                dtdif = float((p.time-pcap[0].time) - dpktime)\n",
    "\n",
    "                diat.append(dtdif)\n",
    "\n",
    "                dpktime = p.time - pcap[0].time\n",
    "\n",
    "                dps.append(int(len(p[IP])))\n",
    "\n",
    "                # <--------- per packet based iat and packet size for first quarter session\n",
    "                if ((p.time - pcap[0].time) <= pcaptime_q):\n",
    "\n",
    "                    dtdif_fq = float((p.time-pcap[0].time) - dpktime_fq)\n",
    "\n",
    "                    diat_fq.append(dtdif_fq)\n",
    "\n",
    "                    dpktime_fq = p.time - pcap[0].time\n",
    "\n",
    "                    dps_fq.append(int(len(p[IP])))\n",
    "\n",
    "                # <--------- per packet based iat and packet size for first half session\n",
    "                if ((p.time - pcap[0].time) <= pcaptime_h):\n",
    "\n",
    "                    dtdif_fh = float((p.time-pcap[0].time) - dpktime_fh)\n",
    "\n",
    "                    diat_fh.append(dtdif_fh)\n",
    "\n",
    "                    dpktime_fh = p.time - pcap[0].time\n",
    "\n",
    "                    dps_fh.append(int(len(p[IP])))\n",
    "\n",
    "                # <---------- per packet based iat and packet size for last half session\n",
    "                if ((p.time - pcap[0].time) > (pcaptime_t - pcaptime_h)) and ((p.time - pcap[0].time) <= pcaptime_t):\n",
    "\n",
    "                    dtdif_lh = float((p.time-pcap[0].time) - dpktime_lh)\n",
    "\n",
    "                    diat_lh.append(dtdif_lh)\n",
    "\n",
    "                    dpktime_lh = p.time - pcap[0].time\n",
    "\n",
    "                    dps_lh.append(int(len(p[IP])))\n",
    "\n",
    "                # <---------- per packet based iat and packet size for last quarter session\n",
    "                if ((p.time - pcap[0].time) > (pcaptime_t - pcaptime_q)) and ((p.time - pcap[0].time) <= pcaptime_t):\n",
    "\n",
    "                    dtdif_lq = float((p.time-pcap[0].time) - dpktime_lq)\n",
    "\n",
    "                    diat_lq.append(dtdif_lq)\n",
    "\n",
    "                    dpktime_lq = p.time - pcap[0].time\n",
    "\n",
    "                    dps_lq.append(int(len(p[IP])))\n",
    "\n",
    "            # uplink-------------> (Server - destination '10.0.0.251')\n",
    "            if (p.haslayer(UDP)) and (p[IP].dst == '10.0.0.251'):\n",
    "\n",
    "                # ---------> per second based: throughput and packet number\n",
    "                if (p.time-pcap[0].time) <= uthreshold and (p.time-pcap[0].time) >= ustart:\n",
    "\n",
    "                    uvolume = uvolume + (int(len(p[IP]))*8)\n",
    "                    upcount = upcount + 1\n",
    "\n",
    "                else:\n",
    "                    utp.append(uvolume/granularity)\n",
    "\n",
    "                    upc.append(upcount)\n",
    "\n",
    "                    uvolume = 0\n",
    "                    upcount = 0\n",
    "\n",
    "                    uvolume = uvolume + (int(len(p[IP]))*8)\n",
    "                    upcount = upcount + 1\n",
    "\n",
    "                    uthreshold = uthreshold + 1\n",
    "                    ustart = ustart + 1\n",
    "\n",
    "                # ---------> per packet based iat and packet size for entire session\n",
    "                utdif = float((p.time - pcap[0].time) - upktime)\n",
    "\n",
    "                uiat.append(utdif)\n",
    "\n",
    "                upktime = p.time - pcap[0].time\n",
    "\n",
    "                ups.append(int(len(p[IP])))\n",
    "\n",
    "                # ---------> per packet based iat and packet size for first quarter session\n",
    "                if ((p.time - pcap[0].time) <= pcaptime_q):\n",
    "\n",
    "                    fq = p.time - pcap[0].time\n",
    "\n",
    "                    utdif_fq = float((p.time-pcap[0].time) - upktime_fq)\n",
    "\n",
    "                    uiat_fq.append(utdif_fq)\n",
    "\n",
    "                    upktime_fq = p.time - pcap[0].time\n",
    "\n",
    "                    ups_fq.append(int(len(p[IP])))\n",
    "\n",
    "                # ---------> per packet based iat and packet size for first half session\n",
    "                if ((p.time - pcap[0].time) <= pcaptime_h):\n",
    "\n",
    "                    fh = p.time - pcap[0].time\n",
    "\n",
    "                    utdif_fh = float((p.time-pcap[0].time) - upktime_fh)\n",
    "\n",
    "                    uiat_fh.append(utdif_fh)\n",
    "\n",
    "                    upktime_fh = p.time - pcap[0].time\n",
    "\n",
    "                    ups_fh.append(int(len(p[IP])))\n",
    "\n",
    "                # ---------> per packet based iat and packet size for last half session\n",
    "                if ((p.time - pcap[0].time) > (pcaptime_t - pcaptime_h)) and ((p.time - pcap[0].time) <= pcaptime_t):\n",
    "\n",
    "                    lh = p.time - pcap[0].time\n",
    "\n",
    "                    utdif_lh = float((p.time-pcap[0].time) - upktime_lh)\n",
    "\n",
    "                    uiat_lh.append(utdif_lh)\n",
    "\n",
    "                    upktime_lh = p.time - pcap[0].time\n",
    "\n",
    "                    ups_lh.append(int(len(p[IP])))\n",
    "\n",
    "                # ---------> per packet based iat and packet size for last quarter session\n",
    "                if ((p.time - pcap[0].time) > (pcaptime_t - pcaptime_q)) and ((p.time - pcap[0].time) <= pcaptime_t):\n",
    "\n",
    "                    lq = p.time - pcap[0].time\n",
    "\n",
    "                    utdif_lq = float((p.time-pcap[0].time) - upktime_lq)\n",
    "\n",
    "                    uiat_lq.append(utdif_lq)\n",
    "\n",
    "                    upktime_lq = p.time - pcap[0].time\n",
    "\n",
    "                    ups_lq.append(int(len(p[IP])))\n",
    "\n",
    "        # define the session lengths for throughput and packet number QoS features\n",
    "        l = len(dtp)\n",
    "        l1 = math.ceil(len(dtp)/2)\n",
    "        l2 = math.ceil(len(dtp)/4)\n",
    "        lu = len(utp)\n",
    "        lu1 = math.ceil(len(utp)/2)\n",
    "        lu2 = math.ceil(len(utp)/4)\n",
    "\n",
    "        print(l)\n",
    "        print(l1)\n",
    "        print(l2)\n",
    "\n",
    "        k = len(dpc)\n",
    "        k1 = math.ceil(len(dpc)/2)\n",
    "        k2 = math.ceil(len(dpc)/4)\n",
    "\n",
    "        print(k)\n",
    "        print(k1)\n",
    "        print(k2)\n",
    "\n",
    "        ku = len(upc)\n",
    "        ku1 = math.ceil(len(upc)/2)\n",
    "        ku2 = math.ceil(len(upc)/4)\n",
    "\n",
    "        print(fq)\n",
    "        print(fh)\n",
    "        print(lq)\n",
    "        print(lh)\n",
    "        print(pcaptime_t - pcaptime_q)\n",
    "        print(pcaptime_t - pcaptime_h)\n",
    "\n",
    "        # insert QoS values for each QoS features\n",
    "\n",
    "        data.loc[0] = [np.mean(dtp),  np.max(dtp),  np.min(dtp),  np.median(dtp),  np.std(dtp),\n",
    "                       np.percentile(dtp, 10),  np.percentile(dtp, 20),  np.percentile(dtp, 30),  np.percentile(dtp, 40),  np.percentile(\n",
    "                           dtp, 50),  np.percentile(dtp, 60),  np.percentile(dtp, 70),  np.percentile(dtp, 80),  np.percentile(dtp, 90),\n",
    "                       np.mean((dtp[0:l2])), np.mean((dtp[0:l1])), np.mean(\n",
    "                           (dtp[l-l2:l])), np.mean((dtp[l-l1:l])),\n",
    "\n",
    "                       np.mean(utp),  np.max(utp),  np.min(\n",
    "                           utp),  np.median(utp),  np.std(utp),\n",
    "                       np.percentile(utp, 10),  np.percentile(utp, 20),  np.percentile(utp, 30),  np.percentile(utp, 40),  np.percentile(\n",
    "                           utp, 50),  np.percentile(utp, 60),  np.percentile(utp, 70),  np.percentile(utp, 80),  np.percentile(utp, 90),\n",
    "                       np.mean((utp[0:lu2])), np.mean((utp[0:lu1])), np.mean(\n",
    "                           (utp[lu-lu2:lu])), np.mean((utp[lu-lu1:lu])),\n",
    "\n",
    "                       np.sum(dpc), np.mean(dpc),  np.max(dpc),  np.min(\n",
    "                           dpc),  np.median(dpc),  np.std(dpc),\n",
    "                       np.percentile(dpc, 10),  np.percentile(dpc, 20),  np.percentile(dpc, 30),  np.percentile(dpc, 40),  np.percentile(\n",
    "                           dpc, 50),  np.percentile(dpc, 60),  np.percentile(dpc, 70),  np.percentile(dpc, 80),  np.percentile(dpc, 90),\n",
    "                       np.sum((dpc[0:k2])), np.sum((dpc[0:k1])), np.sum(\n",
    "                           (dpc[k-k2:k])), np.sum((dpc[k-k1:k])),\n",
    "\n",
    "                       np.sum(upc), np.mean(upc),  np.max(upc),  np.min(\n",
    "                           upc),  np.median(upc),  np.std(upc),\n",
    "                       np.percentile(upc, 10),  np.percentile(upc, 20),  np.percentile(upc, 30),  np.percentile(upc, 40),  np.percentile(\n",
    "                           upc, 50),  np.percentile(upc, 60),  np.percentile(upc, 70),  np.percentile(upc, 80),  np.percentile(upc, 90),\n",
    "                       np.sum((upc[0:ku2])), np.sum((upc[0:ku1])), np.sum(\n",
    "                           (upc[ku-ku2:ku])), np.sum((upc[ku-ku1:ku])),\n",
    "\n",
    "\n",
    "                       np.mean(dps),  np.max(dps),  np.min(\n",
    "                           dps),  np.median(dps),  np.std(dps),\n",
    "                       np.percentile(dps, 10),  np.percentile(dps, 20),  np.percentile(dps, 30),  np.percentile(dps, 40),  np.percentile(\n",
    "                           dps, 50),  np.percentile(dps, 60),  np.percentile(dps, 70),  np.percentile(dps, 80),  np.percentile(dps, 90),\n",
    "                       np.mean(dps_fq), np.mean(dps_fh), np.mean(\n",
    "                           dps_lq), np.mean(dps_lh),\n",
    "\n",
    "\n",
    "                       np.mean(ups),  np.max(ups),  np.min(\n",
    "                           ups),  np.median(ups),  np.std(ups),\n",
    "                       np.percentile(ups, 10),  np.percentile(ups, 20),  np.percentile(ups, 30),  np.percentile(ups, 40),  np.percentile(\n",
    "                           ups, 50),  np.percentile(ups, 60),  np.percentile(ups, 70),  np.percentile(ups, 80),  np.percentile(ups, 90),\n",
    "                       np.mean(ups_fq), np.mean(ups_fh), np.mean(\n",
    "                           ups_lq), np.mean(ups_lh),\n",
    "\n",
    "                       np.mean(diat),  np.max(diat),  np.min(\n",
    "                           diat),  np.median(diat),  np.std(diat),\n",
    "                       np.percentile(diat, 10),  np.percentile(diat, 20),  np.percentile(diat, 30),  np.percentile(diat, 40),  np.percentile(\n",
    "                           diat, 50),  np.percentile(diat, 60),  np.percentile(diat, 70),  np.percentile(diat, 80),  np.percentile(diat, 90),\n",
    "                       np.mean(diat_fq), np.mean(diat_fh), np.mean(\n",
    "                           diat_lq), np.mean(diat_lh),\n",
    "\n",
    "\n",
    "                       np.mean(uiat),  np.max(uiat),  np.min(\n",
    "                           uiat),  np.median(uiat),  np.std(uiat),\n",
    "                       np.percentile(uiat, 10),  np.percentile(uiat, 20),  np.percentile(uiat, 30),  np.percentile(uiat, 40),  np.percentile(\n",
    "                           uiat, 50),  np.percentile(uiat, 60),  np.percentile(uiat, 70),  np.percentile(uiat, 80),  np.percentile(uiat, 90),\n",
    "                       np.mean(uiat_fq), np.mean(uiat_fh), np.mean(\n",
    "                           uiat_lq), np.mean(uiat_lh)\n",
    "\n",
    "\n",
    "\n",
    "                       ]\n",
    "\n",
    "        export_csv = data.to_csv(str(path)+'-pcap.csv')\n",
    "        print('export csv ok')\n",
    "\n",
    "    except:\n",
    "         print(path)\n",
    "         pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145cdb19",
   "metadata": {},
   "source": [
    "#### Configuration over 5G traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1\n",
    "\n",
    "mode = ['5g']\n",
    "\n",
    "net5 = ['static-1', 'static-2', 'static-3',\n",
    "        'static-4', 'static-5']  # mobility for 5g\n",
    "\n",
    "tp_type = ['quic']\n",
    "ap_type = ['http-3_p']\n",
    "sv_type = ['WSGI_caddy']\n",
    "\n",
    "\n",
    "video_id = ['v2']  # ['v2']\n",
    "tl_scheme = ['12x4', '8x4']\n",
    "vp_traces = 5  # 48\n",
    "vp_error = [0, 50, 100]\n",
    "thread = [1]\n",
    "buffer = [2, 4, 6]\n",
    "t_segment = [60]\n",
    "algo = [0, 1]  # adaptation algorithm  FD =0 , FDB = 1\n",
    "\n",
    "bg_traffic = ['no']\n",
    "\n",
    "host = [1]\n",
    "\n",
    "# todo- make nested for loop shorter in an alternative way\n",
    "for it in range(iteration):\n",
    "    for i in mode:\n",
    "        if i == '5g':\n",
    "           for j in net5:\n",
    "               for k in tp_type:\n",
    "                   for l in ap_type:\n",
    "                       for m in sv_type:\n",
    "                           for n in video_id:\n",
    "                               for o in tl_scheme:\n",
    "                                   for p in range(3, vp_traces+1):\n",
    "                                        delay = 5\n",
    "                                        for q in vp_error:\n",
    "                                            for r in thread:\n",
    "                                                for s in buffer:\n",
    "                                                    for t in t_segment:\n",
    "                                                        for u in algo:\n",
    "                                                            for v in bg_traffic:\n",
    "                                                                for w in host:\n",
    "                                                                    path1 = str(i)+'/'+str(j)+'/'+str(k)+'/'+str(l)+'/'+str(m)+'/'+str(n)+'/'+str(\n",
    "                                                                        o)+'/'+'VP-trace-'+str(p)+'/'+str(v)+'-bg_traffic'+'/'+'Exp'+str(it+1)+'/'\n",
    "\n",
    "                                                                    path2 = 'host-'+str(w)+'_ts-'+str(t)+'_thd-'+str(r)+'_vpe-'+str(\n",
    "                                                                        q)+'_algo-'+str(u)+'_bft-'+str(s)+'_delay-'+str(delay)+'/'\n",
    "                                                                    filename = 'host-'+str(w)+'_ts-'+str(t)+'_thd-'+str(r)+'_vpe-'+str(\n",
    "                                                                        q)+'_algo-'+str(u)+'_bft-'+str(s)+'_delay-'+str(delay)\n",
    "                                                                    path = '/media/tariq/Data-House/vrexp/' + \\\n",
    "                                                                        str(path1)+str(path2) + \\\n",
    "                                                                        str(filename)\n",
    "                                                                    #print(path)\n",
    "                                                                    #pcap_filter(path)\n",
    "                                                                    pcap_processing(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b6ee3",
   "metadata": {},
   "source": [
    "#### Configuration over 4G traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314343d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1\n",
    "\n",
    "mode = ['4g']\n",
    "\n",
    "net4 = ['train_new_1', 'static_new_1',\n",
    "        'car_new_1', 'pedestrian_new_1', 'bus_new_1']\n",
    "\n",
    "tp_type = ['quic']\n",
    "ap_type = ['http-3_p']\n",
    "sv_type = ['WSGI_caddy']\n",
    "\n",
    "\n",
    "video_id = ['v2']  # ['v2']\n",
    "tl_scheme = ['12x4', '8x4']\n",
    "vp_traces = 5  # 48\n",
    "vp_error = [0, 50, 100]\n",
    "thread = [1]\n",
    "buffer = [2, 4, 6]\n",
    "t_segment = [60]\n",
    "algo = [0, 1]  # adaptation algorithm  FD =0 , FDB = 1\n",
    "\n",
    "bg_traffic = ['no']\n",
    "\n",
    "host = [1]\n",
    "\n",
    "# todo- make nested for loop shorter in an alternative way\n",
    "for it in range(iteration):\n",
    "    for i in mode:\n",
    "        if i == '4g':\n",
    "           for j in net4:\n",
    "               for k in tp_type:\n",
    "                   for l in ap_type:\n",
    "                       for m in sv_type:\n",
    "                           for n in video_id:\n",
    "                               for o in tl_scheme:\n",
    "                                   for p in range(1, vp_traces+1):\n",
    "                                        delay = 11\n",
    "                                        for q in vp_error:\n",
    "                                            for r in thread:\n",
    "                                                for s in buffer:\n",
    "                                                    for t in t_segment:\n",
    "                                                        for u in algo:\n",
    "                                                            for v in bg_traffic:\n",
    "                                                                for w in host:\n",
    "                                                                    path1 = str(i)+'/'+str(j)+'/'+str(k)+'/'+str(l)+'/'+str(m)+'/'+str(n)+'/'+str(\n",
    "                                                                        o)+'/'+'VP-trace-'+str(p)+'/'+str(v)+'-bg_traffic'+'/'+'Exp'+str(it+1)+'/'\n",
    "\n",
    "                                                                    path2 = 'host-'+str(w)+'_ts-'+str(t)+'_thd-'+str(r)+'_vpe-'+str(\n",
    "                                                                        q)+'_algo-'+str(u)+'_bft-'+str(s)+'_delay-'+str(delay)+'/'\n",
    "                                                                    filename = 'host-'+str(w)+'_ts-'+str(t)+'_thd-'+str(r)+'_vpe-'+str(\n",
    "                                                                        q)+'_algo-'+str(u)+'_bft-'+str(s)+'_delay-'+str(delay)\n",
    "                                                                    path = '/media/tariq/Data-House/vrexp/' + \\\n",
    "                                                                        str(path1)+str(path2) + \\\n",
    "                                                                        str(filename)\n",
    "                                                                    #pcap_filter(path)\n",
    "                                                                    pcap_processing(path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
